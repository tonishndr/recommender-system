# -*- coding: utf-8 -*-
"""mltp_recommender_system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CLqk0GLGK9lCoQlSlvbqSAlNy0ACA7h_

# **Data Understanding**

## **Data Explorations**

Untuk dapat memahami data, kita perlu melakukan explorasi terhadap data-data yang akan digunakan.

Untuk melakukan hal tersebut, kita tentu perlu melakukan import beberapa librari dasar yang dibutuhkan.
"""

# Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import warnings
from pandas.errors import SettingWithCopyWarning
warnings.filterwarnings('ignore', category=SettingWithCopyWarning)

"""Tentukan nama variabel untuk setiap data yang akan digunakan."""

movie = pd.read_csv('/Users/tonisuhendar/One-Hour/learn-ds/dataset/letterboxd-movie/movie_data.csv')
rating = pd.read_csv('/Users/tonisuhendar/One-Hour/learn-ds/dataset/letterboxd-movie/ratings_export.csv')
user = pd.read_csv('/Users/tonisuhendar/One-Hour/learn-ds/dataset/letterboxd-movie/users_export.csv')

"""### **Univariate Exploratory Data Analysis**

#### **Movie Variable**

Menampilkan sebagian baris data dari variabel `Movie`
"""

movie

"""Melihat informasi dari variabel `Movie`"""

movie.info()

"""Mengambil fitu-fitur yang akan digunakan dari variabel `Movie`"""

movie = movie[['movie_id','movie_title','genres','original_language','spoken_languages','production_countries','year_released','popularity']]
movie

"""Mengganti nilai `[]` menjadi  nilai `NaN`"""

movie = movie.replace('[]', np.nan)
movie

"""Deteksi nilai yang hilang"""

movie.isna().sum()

"""Menghapus nilai yang hilang"""

movie = movie.dropna()
movie

"""Menghapus nilai `[]` dan `""` yang terdapat pada setiap fitur"""

movie = movie.applymap(lambda x: re.sub(r'[\[\]]', '', re.sub(r'"(.*?)"', r"\1", str(x))))
movie = movie.reset_index(drop=True)
movie

"""Deteksi nilai yang hilang"""

movie.isna().sum()

"""Deteksi nilai yang unik"""

movie.nunique()

"""Visualisasi judul film menggunakan librari wordcloud"""

from wordcloud import WordCloud

# Data movie_title
movie_titles = movie['movie_title']

# Menggabungkan semua judul film menjadi satu string
text = ' '.join(movie_titles)

# Membuat Word Cloud
wordcloud = WordCloud(width=800, height=400).generate(text)

# Menampilkan Word Cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud Judul Film')
plt.show()

"""#### **Rating Variable**

Menampilkan sebagian baris data dari variabel `Rating`
"""

rating

"""Menghapus fitur yang tidak diinginkan"""

rating = rating.drop('_id', axis=1)
rating

"""Melihat informasi pada variabel `Rating`"""

rating.info()

"""Deteksi nilai yang hilang"""

rating.isna().sum()

"""Mengatasi nilai yang hilang dengan metode drop kemudian memvalidasinya"""

rating = rating.dropna()
rating.isna().sum()

rating

"""Visualisasi rating"""

# Data rating_val
rating_val = rating['rating_val']

# Menghitung jumlah film dalam setiap rating
rating_counts = rating_val.value_counts().sort_index()

# Membuat bar plot
plt.bar(rating_counts.index, rating_counts.values, edgecolor='black')

# Memberikan judul dan label pada sumbu-sumbu
plt.title('Distribusi Rating Film')
plt.xlabel('Rating')
plt.ylabel('Jumlah Film')

# Menambahkan label nilai pada setiap bar
for i, count in enumerate(rating_counts.values):
    plt.text(rating_counts.index[i], count, str(count), ha='center', va='bottom')

# Menampilkan bar plot
plt.show()

"""#### **User Variable**

Menampilkan sebagian baris data dari variabel `User`
"""

user

"""Melihat informasi variabel `User`"""

user.info()

"""Deteksi nilai yang hilang"""

user.isna().sum()

"""## **Data Preprocessing**

Menggabungkan variabel yang akan digunakan untuk tahap pemodelan yaitu variabel `movie` dan `rating`
"""

dataset = movie
dataset = pd.merge(rating, dataset, on='movie_id', how='left')
dataset

"""Mengurutkan ulang fitur-fitur pada variabel `dataset` supaya lebih enak dibaca"""

dataset = dataset[['user_id','rating_val','movie_id','movie_title','genres','original_language','spoken_languages','production_countries','year_released','popularity']]
dataset

"""## **Data Preparation**

Deteksi nilai yang hilang
"""

dataset.isna().sum()

"""Menghapus data yang hilang dan memvalidasinya"""

dataset = dataset.dropna()
dataset.isna().sum()

dataset

"""Deteksi data unik"""

dataset.nunique()

"""Deteksi data duplikat"""

dataset.duplicated().sum()

"""## **Modeling**

### **Content Based Filtering**

Membuat variabel baru untuk modeling dengan teknik content based filtering
"""

cbf_df = dataset[['movie_id','genres']]
cbf_df

"""Deteksi data unik"""

cbf_df.nunique()

"""Deteksi data duplikat"""

cbf_df.duplicated().sum()

"""Menghapus data duplikat"""

cbf_df = cbf_df.drop_duplicates()

"""Deteksi nilai yang hilang"""

cbf_df.isna().sum()

"""Melihat sebagian data dari variabel `df`"""

cbf_df

"""Mengganti ruang kosong(spasi) dengan `_`"""

cbf_df = cbf_df.applymap(lambda x: re.sub(r'\s+', '_', str(x)))
cbf_df

"""Menerapkan teknik Simple Random Sampling untuk mengurangi jumlah sampel"""

# Menentukan ukuran sampel yang diinginkan
ukuran_sampel = int(len(cbf_df) * 0.37)

# Melakukan Simple Random Sampling
cbf_df = cbf_df.sample(n=ukuran_sampel, random_state=100623)
cbf_df # 63209

"""#### TfidfVectorizer & Cosimilarity

Mengekstraksi fitur `genres` dengan metode TF-IDF
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Menginisialisasi TfidfVectorizer
tfidf = TfidfVectorizer()

# Mengubah kolom 'genres' menjadi representasi TF-IDF
genres_tfidf = tfidf.fit_transform(cbf_df['genres'])

# Membuat DataFrame baru dari hasil ekstraksi fitur
df_vectorized = pd.DataFrame(genres_tfidf.toarray(), columns=tfidf.get_feature_names_out())
df_vectorized

"""Mengidentifikasi kemiripan movie_id berdasarkan genrenya"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(df_vectorized)

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama movie_id
cosine_sim_df = pd.DataFrame(cosine_sim, index=cbf_df['movie_id'], columns=cbf_df['movie_id'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap movie_id
cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""Membuat rekomendasi film"""

def get_movie_recommendations(movie_title, similarity_data=cosine_sim_df, items=cbf_df[['movie_id', 'genres']], k=10):
    index = similarity_data.loc[:,movie_title].to_numpy().argpartition(range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop movie_id agar movie_id yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(movie_title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

cbf_df[cbf_df.movie_id.eq('lover-divine')]

get_movie_recommendations('lover-divine')

"""### **Collaborative Filtering**

Membuat variabel baru untuk modeling dengan teknik collaborative filtering
"""

cf_df = dataset[['user_id','movie_id','genres','rating_val']]
cf_df

"""Deteksi data duplikat"""

cf_df.duplicated().sum()

"""Deteksi nilai unik"""

cf_df.nunique()

"""Menerapkan teknik Simple Random Sampling untuk mengurangi jumlah sampel"""

# Menentukan ukuran sampel yang diinginkan
ukuran_sampel = int(len(cf_df) * 0.0060176)

# Melakukan Simple Random Sampling
cf_df = cf_df.sample(n=ukuran_sampel, random_state=130623)
cf_df # 63209

"""Melakukan teknik encoding pada fitur user"""

userid = cf_df['user_id'].unique().tolist()
print('User ID :', userid)

user_to_user_encode = {x: i for i, x in enumerate(userid)}
print('encoded userID : ', user_to_user_encode)

user_encoded_to_user = {i: x for i, x in enumerate(userid)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Melakukan teknik encoding pada fitur movie"""

movieid = cf_df['movie_id'].unique().tolist()
print('Movie ID :', movieid)

movie_to_movie_encode = {x: i for i, x in enumerate(movieid)}
print('encoded MovieID : ', movie_to_movie_encode)

movie_encoded_to_movie = {i: x for i, x in enumerate(movieid)}
print('encoded angka ke MovieID: ', movie_encoded_to_movie)

"""Melakukan teknik mapping terhadap fitur user dan movie ke dataframe"""

# Mapping userID ke dataframe user
cf_df['user'] = cf_df['user_id'].map(user_to_user_encode)

# Mapping placeID ke dataframe resto
cf_df['movie'] = cf_df['movie_id'].map(movie_to_movie_encode)

"""Melakukan pengecekan terhadap jumlah user dan movie"""

num_users = len(user_to_user_encode)
num_movies = len(movie_to_movie_encode)
print('Jumlah User:', num_users)
print('Jumlah Movie:', num_movies)

"""Melihat sebagian isi dari dataframe"""

cf_df

"""Melihat ringkasan statistik dari data dalam dataframe"""

cf_df.describe()

"""Melakukan ipmort librari yang dibutuhkan dalam tahap modeling"""

# Load Surprise libraries
from surprise import Reader, Dataset, accuracy, KNNBasic
from surprise.model_selection import train_test_split

# Membuat dataset dari dataframe
reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(cf_df[['user', 'movie', 'rating_val']], reader)

# Split dataset menjadi data latih dan data uji
trainset, testset = train_test_split(data, test_size=0.2)

# Membuat model UBCF
model = KNNBasic(sim_options={'user_based': True})

# Melatih model menggunakan data latih
model.fit(trainset)

# Melakukan prediksi pada data uji
predictions = model.test(testset)

rmse = accuracy.rmse(predictions)
mae = accuracy.mae(predictions)

# Membuat daftar semua item yang ada dalam dataset
all_items = set(cf_df['movie_id'])

# Memilih pengguna yang akan diberikan rekomendasi
user_id = 'deathproof'

# Mengambil daftar item yang sudah dinilai oleh pengguna
rated_items = set(cf_df[cf_df['user_id'] == user_id]['movie_id'])

# Menghitung item-item yang belum dinilai oleh pengguna
unrated_items = list(all_items - rated_items)

# Membuat prediksi rating untuk item-item yang belum dinilai oleh pengguna
predictions = [model.predict(user_id, item_id) for item_id in unrated_items]

# Menyortir item-item berdasarkan nilai prediksi tertinggi
predictions.sort(reverse=True)

# Mengambil top 10 item teratas
top_10_predictions = predictions[:10]

# Menampilkan rekomendasi untuk pengguna
print("Top 10 Rekomendasi untuk pengguna", user_id, ":")
for prediction in top_10_predictions:
    genres = cf_df[cf_df['movie_id'] == prediction.iid]['genres'].values[0]
    print("Movie:", prediction.iid, '||', "Genres:", genres, '||', "Rating Prediction:", prediction.est)